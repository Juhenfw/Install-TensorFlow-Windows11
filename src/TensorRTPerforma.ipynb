{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4257bbf",
   "metadata": {},
   "source": [
    "# Convert yolo.pt to yolo.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11m.pt')\n",
    "\n",
    "# Export dengan optimasi maksimal untuk speed\n",
    "model.export(\n",
    "    format='engine',\n",
    "    device=0,\n",
    "    half=True,           # FP16 precision untuk speed\n",
    "    batch=32,             # Batch size untuk throughput\n",
    "    workspace=4,         # Workspace memory (GB)\n",
    "    imgsz=640,          # Input size\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd121278",
   "metadata": {},
   "source": [
    "# Test Model Tensorflow yolo.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import queue\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "class BatchedSharedMemorySystem:\n",
    "    def __init__(self, engine_path, video_path, batch_size=32, buffer_size=50):\n",
    "        self.model = YOLO(engine_path)\n",
    "        self.video_path = video_path\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Shared Memory Buffers sesuai flowchart\n",
    "        self.frame_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.detection_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.tracking_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        \n",
    "        # Thread control\n",
    "        self.running = True\n",
    "        \n",
    "        # Tracking state\n",
    "        self.tracks = {}\n",
    "        self.next_track_id = 0\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.stats = {\n",
    "            'camera_fps': 0,\n",
    "            'detection_fps': 0,\n",
    "            'tracking_fps': 0,\n",
    "            'batch_fps': 0,\n",
    "            'camera_frames': 0,\n",
    "            'detection_frames': 0,\n",
    "            'tracking_frames': 0,\n",
    "            'batches_processed': 0,\n",
    "            'start_time': time.time()\n",
    "        }\n",
    "        \n",
    "        # Frame dimensions\n",
    "        self.frame_height = 480\n",
    "        self.frame_width = 640\n",
    "        self.frame_channels = 3\n",
    "    \n",
    "    def camera_thread(self):\n",
    "        \"\"\"Camera Thread - Continuous frame capture ke Frame Buffer\"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 120)\n",
    "        \n",
    "        frame_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"üìπ Camera Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                continue\n",
    "            \n",
    "            # Resize frame\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            \n",
    "            # Add frame to Frame Buffer\n",
    "            if not self.frame_buffer.full():\n",
    "                self.frame_buffer.put((frame.copy(), frame_count, time.time()))\n",
    "                frame_count += 1\n",
    "                self.stats['camera_frames'] += 1\n",
    "            \n",
    "            # Calculate camera FPS\n",
    "            if frame_count % 100 == 0:\n",
    "                elapsed = time.time() - fps_start\n",
    "                self.stats['camera_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                fps_start = time.time()\n",
    "                print(f\"üìπ Camera FPS: {self.stats['camera_fps']:.1f}\")\n",
    "        \n",
    "        cap.release()\n",
    "        print(\"üìπ Camera Thread Stopped\")\n",
    "    \n",
    "    def object_detection_thread(self):\n",
    "        \"\"\"Object Detection Thread - Batch processing 32 frames\"\"\"\n",
    "        detection_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(f\"üîç Object Detection Thread Started (Batch Size: {self.batch_size})\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                frames_batch = []\n",
    "                frame_ids = []\n",
    "                timestamps = []\n",
    "                \n",
    "                # Collect batch_size frames dari Frame Buffer\n",
    "                for _ in range(self.batch_size):\n",
    "                    try:\n",
    "                        frame, frame_id, timestamp = self.frame_buffer.get(timeout=0.1)\n",
    "                        frames_batch.append(frame)\n",
    "                        frame_ids.append(frame_id)\n",
    "                        timestamps.append(timestamp)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                \n",
    "                if len(frames_batch) > 0:\n",
    "                    while len(frames_batch) < self.batch_size:\n",
    "                        frames_batch.append(frames_batch[-1])\n",
    "                        frame_ids.append(frame_ids[-1])\n",
    "                        timestamps.append(timestamps[-1])\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        batch_results = self.model.predict(\n",
    "                            frames_batch,\n",
    "                            device=0,\n",
    "                            conf=0.25,\n",
    "                            iou=0.45,\n",
    "                            verbose=False,\n",
    "                            stream=False\n",
    "                        )\n",
    "                    \n",
    "                    # Put batch results ke Detection Buffer\n",
    "                    for i, (frame, result, frame_id, timestamp) in enumerate(zip(frames_batch, batch_results, frame_ids, timestamps)):\n",
    "                        if not self.detection_buffer.full():\n",
    "                            self.detection_buffer.put((frame, result, frame_id, timestamp))\n",
    "                            detection_count += 1\n",
    "                            self.stats['detection_frames'] += 1\n",
    "                    \n",
    "                    self.stats['batches_processed'] += 1\n",
    "                    \n",
    "                    # Calculate detection FPS\n",
    "                    if detection_count % 100 == 0:\n",
    "                        elapsed = time.time() - fps_start\n",
    "                        self.stats['detection_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                        self.stats['batch_fps'] = (self.stats['batches_processed'] * self.batch_size) / (time.time() - self.stats['start_time'])\n",
    "                        fps_start = time.time()\n",
    "                        print(f\"üîç Detection FPS: {self.stats['detection_fps']:.1f} | Batch FPS: {self.stats['batch_fps']:.1f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Detection error: {e}\")\n",
    "        \n",
    "        print(\"üîç Object Detection Thread Stopped\")\n",
    "    \n",
    "    def object_tracking_thread(self):\n",
    "        \"\"\"Object Tracking Thread - Individual frame tracking\"\"\"\n",
    "        tracking_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"üéØ Object Tracking Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get detection result\n",
    "                frame, detection_result, frame_id, timestamp = self.detection_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Object Tracking per frame\n",
    "                tracked_frame = self.perform_tracking(frame, detection_result, frame_id)\n",
    "                \n",
    "                # Put to Tracking Buffer\n",
    "                if not self.tracking_buffer.full():\n",
    "                    self.tracking_buffer.put((tracked_frame, frame_id, timestamp))\n",
    "                    tracking_count += 1\n",
    "                    self.stats['tracking_frames'] += 1\n",
    "                \n",
    "                # Calculate tracking FPS\n",
    "                if tracking_count % 100 == 0:\n",
    "                    elapsed = time.time() - fps_start\n",
    "                    self.stats['tracking_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                    fps_start = time.time()\n",
    "                    print(f\"üéØ Tracking FPS: {self.stats['tracking_fps']:.1f}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Tracking error: {e}\")\n",
    "        \n",
    "        print(\"üéØ Object Tracking Thread Stopped\")\n",
    "    \n",
    "    def perform_tracking(self, frame, detection_result, frame_id):\n",
    "        \"\"\"Perform object tracking dengan ID assignment\"\"\"\n",
    "        tracked_frame = frame.copy()\n",
    "        \n",
    "        if detection_result.boxes is not None:\n",
    "            boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
    "            confs = detection_result.boxes.conf.cpu().numpy()\n",
    "            classes = detection_result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            current_detections = []\n",
    "            \n",
    "            # Extract detections\n",
    "            for box, conf, cls in zip(boxes, confs, classes):\n",
    "                if conf > 0.25:\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    \n",
    "                    current_detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'center': (center_x, center_y),\n",
    "                        'conf': conf,\n",
    "                        'class': int(cls)\n",
    "                    })\n",
    "            \n",
    "            # Assign track IDs\n",
    "            for detection in current_detections:\n",
    "                track_id = self.assign_track_id(detection)\n",
    "                \n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                \n",
    "                # Draw tracking visualization\n",
    "                color = self.get_track_color(track_id)\n",
    "                cv2.rectangle(tracked_frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Draw track info\n",
    "                label = f\"ID:{track_id} C:{detection['class']} {detection['conf']:.2f}\"\n",
    "                cv2.putText(tracked_frame, label, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Draw center point\n",
    "                cv2.circle(tracked_frame, detection['center'], 3, color, -1)\n",
    "        \n",
    "        return tracked_frame\n",
    "    \n",
    "    def assign_track_id(self, detection):\n",
    "        \"\"\"Assign track ID menggunakan distance-based matching\"\"\"\n",
    "        center = detection['center']\n",
    "        min_distance = float('inf')\n",
    "        assigned_id = None\n",
    "        \n",
    "        # Find closest existing track\n",
    "        for track_id, track_data in list(self.tracks.items()):\n",
    "            if time.time() - track_data['last_seen'] > 2.0:\n",
    "                del self.tracks[track_id]\n",
    "                continue\n",
    "                \n",
    "            track_center = track_data['center']\n",
    "            distance = np.sqrt((center[0] - track_center[0])**2 + (center[1] - track_center[1])**2)\n",
    "            \n",
    "            if distance < min_distance and distance < 80:\n",
    "                min_distance = distance\n",
    "                assigned_id = track_id\n",
    "        \n",
    "        # Create new track if no match\n",
    "        if assigned_id is None:\n",
    "            assigned_id = self.next_track_id\n",
    "            self.next_track_id += 1\n",
    "        \n",
    "        # Update track\n",
    "        self.tracks[assigned_id] = {\n",
    "            'center': center,\n",
    "            'last_seen': time.time(),\n",
    "            'class': detection['class']\n",
    "        }\n",
    "        \n",
    "        return assigned_id\n",
    "    \n",
    "    def get_track_color(self, track_id):\n",
    "        \"\"\"Generate consistent color untuk setiap track ID\"\"\"\n",
    "        colors = [\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 0, 0),    # Blue\n",
    "            (0, 0, 255),    # Red\n",
    "            (255, 255, 0),  # Cyan\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Yellow\n",
    "            (128, 0, 128),  # Purple\n",
    "            (255, 165, 0),  # Orange\n",
    "        ]\n",
    "        return colors[track_id % len(colors)]\n",
    "    \n",
    "    def display_thread(self):\n",
    "        \"\"\"Display thread untuk visualization\"\"\"\n",
    "        print(\"üñ•Ô∏è Display Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get tracked frame from Tracking Buffer\n",
    "                tracked_frame, frame_id, timestamp = self.tracking_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Add performance overlay\n",
    "                self.add_performance_overlay(tracked_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Batched Multi-Thread Object Detection & Tracking', tracked_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.running = False\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.tracks.clear()\n",
    "                    self.next_track_id = 0\n",
    "                    print(\"üîÑ Tracking reset\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"üñ•Ô∏è Display Thread Stopped\")\n",
    "    \n",
    "    def add_performance_overlay(self, frame):\n",
    "        \"\"\"Add performance statistics overlay\"\"\"\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        \n",
    "        # Calculate overall FPS (bottleneck from all thread)\n",
    "        overall_fps = min(self.stats['camera_fps'], self.stats['detection_fps'], self.stats['tracking_fps'])\n",
    "        \n",
    "        stats_text = [\n",
    "            f\"Camera FPS: {self.stats['camera_fps']:.1f}\",\n",
    "            f\"Detection FPS: {self.stats['detection_fps']:.1f}\",\n",
    "            f\"Batch FPS: {self.stats['batch_fps']:.1f}\",\n",
    "            f\"Tracking FPS: {self.stats['tracking_fps']:.1f}\",\n",
    "            f\"Overall FPS: {overall_fps:.1f}\",\n",
    "            f\"Batch Size: {self.batch_size}\",\n",
    "            f\"Batches Processed: {self.stats['batches_processed']}\",\n",
    "            f\"Active Tracks: {len(self.tracks)}\",\n",
    "            f\"Buffer: F{self.frame_buffer.qsize()}/D{self.detection_buffer.qsize()}/T{self.tracking_buffer.qsize()}\",\n",
    "            f\"Runtime: {elapsed:.1f}s\"\n",
    "        ]\n",
    "        \n",
    "        # Background for text\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5, 5), (400, 220), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Add text\n",
    "        for i, text in enumerate(stats_text):\n",
    "            y_pos = 20 + (i * 20)\n",
    "            color = (0, 255, 0) if \"FPS\" in text and float(text.split(\":\")[1].strip()) > 100 else (0, 255, 255)\n",
    "            cv2.putText(frame, text, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Success indicator\n",
    "        if self.stats['batch_fps'] > 200:\n",
    "            cv2.putText(frame, \"üéâ TARGET 200+ BATCH FPS ACHIEVED!\", (10, 250), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"üöÄ Starting Batched Multi-Thread Object Detection & Tracking System\")\n",
    "        print(f\"Architecture: Camera ‚Üí Frame Buffer ‚Üí Batch Detection (32) ‚Üí Detection Buffer ‚Üí Tracking ‚Üí Tracking Buffer ‚Üí Display\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(\"Press 'q' to quit, 'r' to reset tracking\")\n",
    "        \n",
    "        # Start all threads\n",
    "        threads = [\n",
    "            threading.Thread(target=self.camera_thread, daemon=True, name=\"CameraThread\"),\n",
    "            threading.Thread(target=self.object_detection_thread, daemon=True, name=\"BatchDetectionThread\"),\n",
    "            threading.Thread(target=self.object_tracking_thread, daemon=True, name=\"TrackingThread\"),\n",
    "            threading.Thread(target=self.display_thread, daemon=True, name=\"DisplayThread\")\n",
    "        ]\n",
    "        \n",
    "        # Start threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "            print(f\"‚úÖ {thread.name} started\")\n",
    "        \n",
    "        try:\n",
    "            # Monitor system performance\n",
    "            while self.running:\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Check target achievement\n",
    "                if self.stats['batch_fps'] > 200:\n",
    "                    print(f\"üéâ BATCH TARGET ACHIEVED: {self.stats['batch_fps']:.1f} FPS!\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Stopping system...\")\n",
    "            self.running = False\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        for thread in threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=2.0)\n",
    "                print(f\"‚úÖ {thread.name} stopped\")\n",
    "        \n",
    "        # Final statistics\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        print(f\"\\nüìä Final Statistics:\")\n",
    "        print(f\"Runtime: {elapsed:.2f}s\")\n",
    "        print(f\"Camera frames: {self.stats['camera_frames']}\")\n",
    "        print(f\"Detection frames: {self.stats['detection_frames']}\")\n",
    "        print(f\"Tracking frames: {self.stats['tracking_frames']}\")\n",
    "        print(f\"Batches processed: {self.stats['batches_processed']}\")\n",
    "        print(f\"Final Camera FPS: {self.stats['camera_fps']:.2f}\")\n",
    "        print(f\"Final Detection FPS: {self.stats['detection_fps']:.2f}\")\n",
    "        print(f\"Final Batch FPS: {self.stats['batch_fps']:.2f}\")\n",
    "        print(f\"Final Tracking FPS: {self.stats['tracking_fps']:.2f}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    engine_path = \"yolo11m.engine\"  # use model TensorRT\n",
    "    # engine_path = \"yolo11m.pt\"\n",
    "    video_path = \"C:/Users/JuhenFW/Downloads/4K Road traffic video for object detection and tracking - free download now.mp4/4K Road traffic video for object detection and tracking - free download now.mp4\"\n",
    "    \n",
    "    # Batch size 32\n",
    "    batch_size = 32\n",
    "    buffer_size = 50\n",
    "    \n",
    "    system = BatchedSharedMemorySystem(engine_path, video_path, batch_size, buffer_size)\n",
    "    system.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
