{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4257bbf",
   "metadata": {},
   "source": [
    "# Convert yolo.pt to yolo.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3fbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.151  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,091,712 parameters, 0 gradients, 68.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11m.pt' with input shape (4, 3, 640, 640) BCHW and output shape(s) (4, 84, 8400) (38.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  3.7s, saved as 'yolo11m.onnx' (76.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.10.0.31...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(4, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(4, 84, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as yolo11m.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success  488.7s, saved as 'yolo11m.engine' (43.3 MB)\n",
      "\n",
      "Export complete (489.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\JuhenFW\\VSCODE\\myproject\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11m.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=yolo11m.engine imgsz=640 data=/ultralytics/ultralytics/cfg/datasets/coco.yaml half \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11m.engine'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11m.pt')\n",
    "\n",
    "# Export dengan optimasi maksimal untuk speed\n",
    "model.export(\n",
    "    format='engine',\n",
    "    device=0,\n",
    "    half=True,           # FP16 precision untuk speed\n",
    "    batch=4,             # Batch size untuk throughput\n",
    "    workspace=4,         # Workspace memory (GB)\n",
    "    imgsz=640,          # Input size\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd121278",
   "metadata": {},
   "source": [
    "# Test Model Tensorflow yolo.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f177fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Tracking FPS: 71.4\n",
      "ğŸ“¹ Camera FPS: 66.5\n",
      "ğŸ¯ Tracking FPS: 71.6\n",
      "ğŸ“¹ Camera FPS: 62.1\n",
      "ğŸ¯ Tracking FPS: 72.5\n",
      "ğŸ“¹ Camera FPS: 71.9\n",
      "ğŸ¯ Tracking FPS: 75.8\n",
      "ğŸ“¹ Camera FPS: 87.0\n",
      "ğŸ” Detection FPS: 9.3 | Batch FPS: 93.4\n",
      "ğŸ¯ Tracking FPS: 132.7\n",
      "ğŸ“¹ Camera FPS: 173.1\n",
      "ğŸ“¹ Camera FPS: 186.3\n",
      "ğŸ¯ Object Tracking Thread Stopped\n",
      "ğŸ“¹ Camera Thread Stopped\n",
      "âœ… CameraThread stopped\n",
      "ğŸ–¥ï¸ Display Thread Stopped\n",
      "ğŸ” Object Detection Thread Stopped\n",
      "âœ… BatchDetectionThread stopped\n",
      "\n",
      "ğŸ“Š Final Statistics:\n",
      "Runtime: 35.58s\n",
      "Camera frames: 3415\n",
      "Detection frames: 3391\n",
      "Tracking frames: 2677\n",
      "Batches processed: 106\n",
      "Final Camera FPS: 186.29\n",
      "Final Detection FPS: 9.31\n",
      "Final Batch FPS: 93.41\n",
      "Final Tracking FPS: 132.70\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import queue\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "class BatchedSharedMemorySystem:\n",
    "    def __init__(self, engine_path, video_path, batch_size=32, buffer_size=50):\n",
    "        self.model = YOLO(engine_path)\n",
    "        self.video_path = video_path\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Shared Memory Buffers sesuai flowchart\n",
    "        self.frame_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.detection_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.tracking_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        \n",
    "        # Thread control\n",
    "        self.running = True\n",
    "        \n",
    "        # Tracking state\n",
    "        self.tracks = {}\n",
    "        self.next_track_id = 0\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.stats = {\n",
    "            'camera_fps': 0,\n",
    "            'detection_fps': 0,\n",
    "            'tracking_fps': 0,\n",
    "            'batch_fps': 0,\n",
    "            'camera_frames': 0,\n",
    "            'detection_frames': 0,\n",
    "            'tracking_frames': 0,\n",
    "            'batches_processed': 0,\n",
    "            'start_time': time.time()\n",
    "        }\n",
    "        \n",
    "        # Frame dimensions\n",
    "        self.frame_height = 480\n",
    "        self.frame_width = 640\n",
    "        self.frame_channels = 3\n",
    "    \n",
    "    def camera_thread(self):\n",
    "        \"\"\"Camera Thread - Continuous frame capture ke Frame Buffer\"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 120)\n",
    "        \n",
    "        frame_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ“¹ Camera Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                continue\n",
    "            \n",
    "            # Resize frame\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            \n",
    "            # Add frame to Frame Buffer\n",
    "            if not self.frame_buffer.full():\n",
    "                self.frame_buffer.put((frame.copy(), frame_count, time.time()))\n",
    "                frame_count += 1\n",
    "                self.stats['camera_frames'] += 1\n",
    "            \n",
    "            # Calculate camera FPS\n",
    "            if frame_count % 100 == 0:\n",
    "                elapsed = time.time() - fps_start\n",
    "                self.stats['camera_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                fps_start = time.time()\n",
    "                print(f\"ğŸ“¹ Camera FPS: {self.stats['camera_fps']:.1f}\")\n",
    "        \n",
    "        cap.release()\n",
    "        print(\"ğŸ“¹ Camera Thread Stopped\")\n",
    "    \n",
    "    def object_detection_thread(self):\n",
    "        \"\"\"Object Detection Thread - Batch processing 32 frames\"\"\"\n",
    "        detection_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(f\"ğŸ” Object Detection Thread Started (Batch Size: {self.batch_size})\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                frames_batch = []\n",
    "                frame_ids = []\n",
    "                timestamps = []\n",
    "                \n",
    "                # Collect batch_size frames dari Frame Buffer\n",
    "                for _ in range(self.batch_size):\n",
    "                    try:\n",
    "                        frame, frame_id, timestamp = self.frame_buffer.get(timeout=0.1)\n",
    "                        frames_batch.append(frame)\n",
    "                        frame_ids.append(frame_id)\n",
    "                        timestamps.append(timestamp)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                \n",
    "                if len(frames_batch) > 0:\n",
    "                    while len(frames_batch) < self.batch_size:\n",
    "                        frames_batch.append(frames_batch[-1])\n",
    "                        frame_ids.append(frame_ids[-1])\n",
    "                        timestamps.append(timestamps[-1])\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        batch_results = self.model.predict(\n",
    "                            frames_batch,\n",
    "                            device=0,\n",
    "                            conf=0.25,\n",
    "                            iou=0.45,\n",
    "                            verbose=False,\n",
    "                            stream=False\n",
    "                        )\n",
    "                    \n",
    "                    # Put batch results ke Detection Buffer\n",
    "                    for i, (frame, result, frame_id, timestamp) in enumerate(zip(frames_batch, batch_results, frame_ids, timestamps)):\n",
    "                        if not self.detection_buffer.full():\n",
    "                            self.detection_buffer.put((frame, result, frame_id, timestamp))\n",
    "                            detection_count += 1\n",
    "                            self.stats['detection_frames'] += 1\n",
    "                    \n",
    "                    self.stats['batches_processed'] += 1\n",
    "                    \n",
    "                    # Calculate detection FPS\n",
    "                    if detection_count % 100 == 0:\n",
    "                        elapsed = time.time() - fps_start\n",
    "                        self.stats['detection_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                        self.stats['batch_fps'] = (self.stats['batches_processed'] * self.batch_size) / (time.time() - self.stats['start_time'])\n",
    "                        fps_start = time.time()\n",
    "                        print(f\"ğŸ” Detection FPS: {self.stats['detection_fps']:.1f} | Batch FPS: {self.stats['batch_fps']:.1f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Detection error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ” Object Detection Thread Stopped\")\n",
    "    \n",
    "    def object_tracking_thread(self):\n",
    "        \"\"\"Object Tracking Thread - Individual frame tracking\"\"\"\n",
    "        tracking_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get detection result\n",
    "                frame, detection_result, frame_id, timestamp = self.detection_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Object Tracking per frame\n",
    "                tracked_frame = self.perform_tracking(frame, detection_result, frame_id)\n",
    "                \n",
    "                # Put to Tracking Buffer\n",
    "                if not self.tracking_buffer.full():\n",
    "                    self.tracking_buffer.put((tracked_frame, frame_id, timestamp))\n",
    "                    tracking_count += 1\n",
    "                    self.stats['tracking_frames'] += 1\n",
    "                \n",
    "                # Calculate tracking FPS\n",
    "                if tracking_count % 100 == 0:\n",
    "                    elapsed = time.time() - fps_start\n",
    "                    self.stats['tracking_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                    fps_start = time.time()\n",
    "                    print(f\"ğŸ¯ Tracking FPS: {self.stats['tracking_fps']:.1f}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Tracking error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Stopped\")\n",
    "    \n",
    "    def perform_tracking(self, frame, detection_result, frame_id):\n",
    "        \"\"\"Perform object tracking dengan ID assignment\"\"\"\n",
    "        tracked_frame = frame.copy()\n",
    "        \n",
    "        if detection_result.boxes is not None:\n",
    "            boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
    "            confs = detection_result.boxes.conf.cpu().numpy()\n",
    "            classes = detection_result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            current_detections = []\n",
    "            \n",
    "            # Extract detections\n",
    "            for box, conf, cls in zip(boxes, confs, classes):\n",
    "                if conf > 0.25:\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    \n",
    "                    current_detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'center': (center_x, center_y),\n",
    "                        'conf': conf,\n",
    "                        'class': int(cls)\n",
    "                    })\n",
    "            \n",
    "            # Assign track IDs\n",
    "            for detection in current_detections:\n",
    "                track_id = self.assign_track_id(detection)\n",
    "                \n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                \n",
    "                # Draw tracking visualization\n",
    "                color = self.get_track_color(track_id)\n",
    "                cv2.rectangle(tracked_frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Draw track info\n",
    "                label = f\"ID:{track_id} C:{detection['class']} {detection['conf']:.2f}\"\n",
    "                cv2.putText(tracked_frame, label, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Draw center point\n",
    "                cv2.circle(tracked_frame, detection['center'], 3, color, -1)\n",
    "        \n",
    "        return tracked_frame\n",
    "    \n",
    "    def assign_track_id(self, detection):\n",
    "        \"\"\"Assign track ID menggunakan distance-based matching\"\"\"\n",
    "        center = detection['center']\n",
    "        min_distance = float('inf')\n",
    "        assigned_id = None\n",
    "        \n",
    "        # Find closest existing track\n",
    "        for track_id, track_data in list(self.tracks.items()):\n",
    "            if time.time() - track_data['last_seen'] > 2.0:\n",
    "                del self.tracks[track_id]\n",
    "                continue\n",
    "                \n",
    "            track_center = track_data['center']\n",
    "            distance = np.sqrt((center[0] - track_center[0])**2 + (center[1] - track_center[1])**2)\n",
    "            \n",
    "            if distance < min_distance and distance < 80:\n",
    "                min_distance = distance\n",
    "                assigned_id = track_id\n",
    "        \n",
    "        # Create new track if no match\n",
    "        if assigned_id is None:\n",
    "            assigned_id = self.next_track_id\n",
    "            self.next_track_id += 1\n",
    "        \n",
    "        # Update track\n",
    "        self.tracks[assigned_id] = {\n",
    "            'center': center,\n",
    "            'last_seen': time.time(),\n",
    "            'class': detection['class']\n",
    "        }\n",
    "        \n",
    "        return assigned_id\n",
    "    \n",
    "    def get_track_color(self, track_id):\n",
    "        \"\"\"Generate consistent color untuk setiap track ID\"\"\"\n",
    "        colors = [\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 0, 0),    # Blue\n",
    "            (0, 0, 255),    # Red\n",
    "            (255, 255, 0),  # Cyan\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Yellow\n",
    "            (128, 0, 128),  # Purple\n",
    "            (255, 165, 0),  # Orange\n",
    "        ]\n",
    "        return colors[track_id % len(colors)]\n",
    "    \n",
    "    def display_thread(self):\n",
    "        \"\"\"Display thread untuk visualization\"\"\"\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get tracked frame from Tracking Buffer\n",
    "                tracked_frame, frame_id, timestamp = self.tracking_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Add performance overlay\n",
    "                self.add_performance_overlay(tracked_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Object Detection & Tracking', tracked_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.running = False\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.tracks.clear()\n",
    "                    self.next_track_id = 0\n",
    "                    print(\"ğŸ”„ Tracking reset\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Stopped\")\n",
    "    \n",
    "    def add_performance_overlay(self, frame):\n",
    "        \"\"\"Add performance statistics overlay\"\"\"\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        \n",
    "        # Calculate overall FPS (bottleneck from all thread)\n",
    "        overall_fps = min(self.stats['camera_fps'], self.stats['detection_fps'], self.stats['tracking_fps'])\n",
    "        \n",
    "        stats_text = [\n",
    "            f\"Camera FPS: {self.stats['camera_fps']:.1f}\",\n",
    "            f\"Detection FPS: {self.stats['detection_fps']:.1f}\",\n",
    "            f\"Batch FPS: {self.stats['batch_fps']:.1f}\",\n",
    "            f\"Tracking FPS: {self.stats['tracking_fps']:.1f}\",\n",
    "            f\"Overall FPS: {overall_fps:.1f}\",\n",
    "            f\"Batch Size: {self.batch_size}\",\n",
    "            f\"Batches Processed: {self.stats['batches_processed']}\",\n",
    "            f\"Active Tracks: {len(self.tracks)}\",\n",
    "            f\"Buffer: F{self.frame_buffer.qsize()}/D{self.detection_buffer.qsize()}/T{self.tracking_buffer.qsize()}\",\n",
    "            f\"Runtime: {elapsed:.1f}s\"\n",
    "        ]\n",
    "        \n",
    "        # Background for text\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5, 5), (400, 220), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Add text\n",
    "        for i, text in enumerate(stats_text):\n",
    "            y_pos = 20 + (i * 20)\n",
    "            color = (0, 255, 0) if \"FPS\" in text and float(text.split(\":\")[1].strip()) > 100 else (0, 255, 255)\n",
    "            cv2.putText(frame, text, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Success indicator\n",
    "        if self.stats['batch_fps'] > 200:\n",
    "            cv2.putText(frame, \"ğŸ‰ TARGET 200+ BATCH FPS ACHIEVED!\", (10, 250), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"ğŸš€ Starting Batched Multi-Thread Object Detection & Tracking System\")\n",
    "        print(f\"Architecture: Camera â†’ Frame Buffer â†’ Batch Detection (32) â†’ Detection Buffer â†’ Tracking â†’ Tracking Buffer â†’ Display\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(\"Press 'q' to quit, 'r' to reset tracking\")\n",
    "        \n",
    "        # Start all threads\n",
    "        threads = [\n",
    "            threading.Thread(target=self.camera_thread, daemon=True, name=\"CameraThread\"),\n",
    "            threading.Thread(target=self.object_detection_thread, daemon=True, name=\"BatchDetectionThread\"),\n",
    "            threading.Thread(target=self.object_tracking_thread, daemon=True, name=\"TrackingThread\"),\n",
    "            threading.Thread(target=self.display_thread, daemon=True, name=\"DisplayThread\")\n",
    "        ]\n",
    "        \n",
    "        # Start threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "            print(f\"âœ… {thread.name} started\")\n",
    "        \n",
    "        try:\n",
    "            # Monitor system performance\n",
    "            while self.running:\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Check target achievement\n",
    "                if self.stats['batch_fps'] > 200:\n",
    "                    print(f\"ğŸ‰ BATCH TARGET ACHIEVED: {self.stats['batch_fps']:.1f} FPS!\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nâ¹ï¸ Stopping system...\")\n",
    "            self.running = False\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        for thread in threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=2.0)\n",
    "                print(f\"âœ… {thread.name} stopped\")\n",
    "        \n",
    "        # Final statistics\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        print(f\"\\nğŸ“Š Final Statistics:\")\n",
    "        print(f\"Runtime: {elapsed:.2f}s\")\n",
    "        print(f\"Camera frames: {self.stats['camera_frames']}\")\n",
    "        print(f\"Detection frames: {self.stats['detection_frames']}\")\n",
    "        print(f\"Tracking frames: {self.stats['tracking_frames']}\")\n",
    "        print(f\"Batches processed: {self.stats['batches_processed']}\")\n",
    "        print(f\"Final Camera FPS: {self.stats['camera_fps']:.2f}\")\n",
    "        print(f\"Final Detection FPS: {self.stats['detection_fps']:.2f}\")\n",
    "        print(f\"Final Batch FPS: {self.stats['batch_fps']:.2f}\")\n",
    "        print(f\"Final Tracking FPS: {self.stats['tracking_fps']:.2f}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    engine_path = \"yolo11m.engine\"  # use model TensorRT\n",
    "    # engine_path = \"yolo11m.pt\"\n",
    "    video_path = \"C:/Users/JuhenFW/Downloads/4K Road traffic video for object detection and tracking - free download now.mp4/4K Road traffic video for object detection and tracking - free download now.mp4\"\n",
    "    \n",
    "    # Batch size 32\n",
    "    batch_size = 32\n",
    "    buffer_size = 50\n",
    "    \n",
    "    system = BatchedSharedMemorySystem(engine_path, video_path, batch_size, buffer_size)\n",
    "    system.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08760765",
   "metadata": {},
   "source": [
    "# For WebCam - Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4decbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "ğŸš€ Starting Batched Multi-Thread Webcam Detection & Tracking System\n",
      "Architecture: Webcam â†’ Frame Buffer â†’ Batch Detection (4) â†’ Detection Buffer â†’ Tracking â†’ Tracking Buffer â†’ Display\n",
      "Batch Size: 4\n",
      "Controls:\n",
      "  'q' - Quit\n",
      "  'r' - Reset tracking\n",
      "  's' - Save screenshot\n",
      "âœ… WebcamThread started\n",
      "ğŸ” Object Detection Thread Started (Batch Size: 4)\n",
      "âœ… BatchDetectionThread started\n",
      "ğŸ¯ Object Tracking Thread Started\n",
      "âœ… TrackingThread started\n",
      "ğŸ–¥ï¸ Display Thread Started\n",
      "âœ… DisplayThread started\n",
      "ğŸ“¹ Webcam Thread Started\n",
      "Loading C:\\Users\\JuhenFW\\VSCODE\\myproject\\yolo11s.engine for TensorRT inference...\n",
      "ğŸ“¹ Camera FPS: 25.6\n",
      "ğŸ” Detection FPS: 14.0 | Batch FPS: 14.0\n",
      "ğŸ¯ Tracking FPS: 14.0\n",
      "ğŸ“¹ Camera FPS: 29.9\n",
      "ğŸ” Detection FPS: 30.0 | Batch FPS: 19.1\n",
      "ğŸ¯ Tracking FPS: 30.0\n",
      "ğŸ“¹ Camera FPS: 29.8\n",
      "ğŸ” Detection FPS: 29.8 | Batch FPS: 21.7\n",
      "ğŸ¯ Tracking FPS: 29.8\n",
      "ğŸ“¹ Camera FPS: 30.4\n",
      "ğŸ” Detection FPS: 30.4 | Batch FPS: 23.4\n",
      "ğŸ¯ Tracking FPS: 30.4\n",
      "\n",
      "â¹ï¸ Stopping system...\n",
      "ğŸ¯ Object Tracking Thread Stopped\n",
      "ğŸ–¥ï¸ Display Thread Stopped\n",
      "ğŸ” Detection FPS: 23.7 | Batch FPS: 23.4\n",
      "ğŸ” Object Detection Thread Stopped\n",
      "ğŸ“¹ Camera Thread Stopped\n",
      "âœ… WebcamThread stopped\n",
      "\n",
      "ğŸ“Š Final Statistics:\n",
      "Runtime: 21.47s\n",
      "Camera frames: 498\n",
      "Detection frames: 500\n",
      "Tracking frames: 496\n",
      "Batches processed: 125\n",
      "Final Camera FPS: 30.40\n",
      "Final Detection FPS: 23.73\n",
      "Final Batch FPS: 23.45\n",
      "Final Tracking FPS: 30.38\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import queue\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "class BatchedWebcamSystem:\n",
    "    def __init__(self, engine_path, batch_size=32, buffer_size=50):\n",
    "        self.model = YOLO(engine_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Shared Memory Buffers sesuai flowchart\n",
    "        self.frame_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.detection_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.tracking_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        \n",
    "        # Thread control\n",
    "        self.running = True\n",
    "        \n",
    "        # Tracking state\n",
    "        self.tracks = {}\n",
    "        self.next_track_id = 0\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.stats = {\n",
    "            'camera_fps': 0,\n",
    "            'detection_fps': 0,\n",
    "            'tracking_fps': 0,\n",
    "            'batch_fps': 0,\n",
    "            'camera_frames': 0,\n",
    "            'detection_frames': 0,\n",
    "            'tracking_frames': 0,\n",
    "            'batches_processed': 0,\n",
    "            'start_time': time.time()\n",
    "        }\n",
    "        \n",
    "        # Frame dimensions\n",
    "        self.frame_height = 480\n",
    "        self.frame_width = 640\n",
    "        self.frame_channels = 3\n",
    "    \n",
    "    def camera_thread(self):\n",
    "        \"\"\"Camera Thread - Continuous webcam capture ke Frame Buffer\"\"\"\n",
    "        # PERUBAHAN UTAMA: Menggunakan webcam (index 0) alih-alih video file\n",
    "        cap = cv2.VideoCapture(0)  # Webcam default\n",
    "        \n",
    "        # Set webcam properties untuk performa optimal\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 60)  # Set FPS tinggi untuk webcam\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce latency\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"âŒ Error: Cannot open webcam\")\n",
    "            self.running = False\n",
    "            return\n",
    "        \n",
    "        frame_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ“¹ Webcam Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"âŒ Error: Cannot read from webcam\")\n",
    "                break\n",
    "            \n",
    "            # Resize frame untuk konsistensi\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            \n",
    "            # Add frame to Frame Buffer\n",
    "            if not self.frame_buffer.full():\n",
    "                self.frame_buffer.put((frame.copy(), frame_count, time.time()))\n",
    "                frame_count += 1\n",
    "                self.stats['camera_frames'] += 1\n",
    "            else:\n",
    "                # Skip frame jika buffer penuh (untuk real-time performance)\n",
    "                pass\n",
    "            \n",
    "            # Calculate camera FPS\n",
    "            if frame_count % 100 == 0:\n",
    "                elapsed = time.time() - fps_start\n",
    "                self.stats['camera_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                fps_start = time.time()\n",
    "                print(f\"ğŸ“¹ Camera FPS: {self.stats['camera_fps']:.1f}\")\n",
    "        \n",
    "        cap.release()\n",
    "        print(\"ğŸ“¹ Camera Thread Stopped\")\n",
    "    \n",
    "    def object_detection_thread(self):\n",
    "        \"\"\"Object Detection Thread - Batch processing frames\"\"\"\n",
    "        detection_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(f\"ğŸ” Object Detection Thread Started (Batch Size: {self.batch_size})\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                frames_batch = []\n",
    "                frame_ids = []\n",
    "                timestamps = []\n",
    "                \n",
    "                # Collect batch_size frames dari Frame Buffer\n",
    "                for _ in range(self.batch_size):\n",
    "                    try:\n",
    "                        frame, frame_id, timestamp = self.frame_buffer.get(timeout=0.1)\n",
    "                        frames_batch.append(frame)\n",
    "                        frame_ids.append(frame_id)\n",
    "                        timestamps.append(timestamp)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                \n",
    "                if len(frames_batch) > 0:\n",
    "                    # Pad batch jika kurang dari batch_size\n",
    "                    while len(frames_batch) < self.batch_size:\n",
    "                        frames_batch.append(frames_batch[-1])\n",
    "                        frame_ids.append(frame_ids[-1])\n",
    "                        timestamps.append(timestamps[-1])\n",
    "                    \n",
    "                    # Run batch inference\n",
    "                    with torch.no_grad():\n",
    "                        batch_results = self.model.predict(\n",
    "                            frames_batch,\n",
    "                            device=0,\n",
    "                            conf=0.25,\n",
    "                            iou=0.45,\n",
    "                            verbose=False,\n",
    "                            stream=False\n",
    "                        )\n",
    "                    \n",
    "                    # Put batch results ke Detection Buffer\n",
    "                    for i, (frame, result, frame_id, timestamp) in enumerate(zip(frames_batch, batch_results, frame_ids, timestamps)):\n",
    "                        if not self.detection_buffer.full():\n",
    "                            self.detection_buffer.put((frame, result, frame_id, timestamp))\n",
    "                            detection_count += 1\n",
    "                            self.stats['detection_frames'] += 1\n",
    "                    \n",
    "                    self.stats['batches_processed'] += 1\n",
    "                    \n",
    "                    # Calculate detection FPS\n",
    "                    if detection_count % 100 == 0:\n",
    "                        elapsed = time.time() - fps_start\n",
    "                        self.stats['detection_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                        self.stats['batch_fps'] = (self.stats['batches_processed'] * self.batch_size) / (time.time() - self.stats['start_time'])\n",
    "                        fps_start = time.time()\n",
    "                        print(f\"ğŸ” Detection FPS: {self.stats['detection_fps']:.1f} | Batch FPS: {self.stats['batch_fps']:.1f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Detection error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ” Object Detection Thread Stopped\")\n",
    "    \n",
    "    def object_tracking_thread(self):\n",
    "        \"\"\"Object Tracking Thread - Individual frame tracking\"\"\"\n",
    "        tracking_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get detection result\n",
    "                frame, detection_result, frame_id, timestamp = self.detection_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Object Tracking per frame\n",
    "                tracked_frame = self.perform_tracking(frame, detection_result, frame_id)\n",
    "                \n",
    "                # Put to Tracking Buffer\n",
    "                if not self.tracking_buffer.full():\n",
    "                    self.tracking_buffer.put((tracked_frame, frame_id, timestamp))\n",
    "                    tracking_count += 1\n",
    "                    self.stats['tracking_frames'] += 1\n",
    "                \n",
    "                # Calculate tracking FPS\n",
    "                if tracking_count % 100 == 0:\n",
    "                    elapsed = time.time() - fps_start\n",
    "                    self.stats['tracking_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                    fps_start = time.time()\n",
    "                    print(f\"ğŸ¯ Tracking FPS: {self.stats['tracking_fps']:.1f}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Tracking error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Stopped\")\n",
    "    \n",
    "    def perform_tracking(self, frame, detection_result, frame_id):\n",
    "        \"\"\"Perform object tracking dengan ID assignment\"\"\"\n",
    "        tracked_frame = frame.copy()\n",
    "        \n",
    "        if detection_result.boxes is not None:\n",
    "            boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
    "            confs = detection_result.boxes.conf.cpu().numpy()\n",
    "            classes = detection_result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            current_detections = []\n",
    "            \n",
    "            # Extract detections\n",
    "            for box, conf, cls in zip(boxes, confs, classes):\n",
    "                if conf > 0.25:\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    \n",
    "                    current_detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'center': (center_x, center_y),\n",
    "                        'conf': conf,\n",
    "                        'class': int(cls)\n",
    "                    })\n",
    "            \n",
    "            # Assign track IDs\n",
    "            for detection in current_detections:\n",
    "                track_id = self.assign_track_id(detection)\n",
    "                \n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                \n",
    "                # Draw tracking visualization\n",
    "                color = self.get_track_color(track_id)\n",
    "                cv2.rectangle(tracked_frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Draw track info\n",
    "                label = f\"ID:{track_id} C:{detection['class']} {detection['conf']:.2f}\"\n",
    "                cv2.putText(tracked_frame, label, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Draw center point\n",
    "                cv2.circle(tracked_frame, detection['center'], 3, color, -1)\n",
    "        \n",
    "        return tracked_frame\n",
    "    \n",
    "    def assign_track_id(self, detection):\n",
    "        \"\"\"Assign track ID menggunakan distance-based matching\"\"\"\n",
    "        center = detection['center']\n",
    "        min_distance = float('inf')\n",
    "        assigned_id = None\n",
    "        \n",
    "        # Find closest existing track\n",
    "        for track_id, track_data in list(self.tracks.items()):\n",
    "            if time.time() - track_data['last_seen'] > 2.0:\n",
    "                del self.tracks[track_id]\n",
    "                continue\n",
    "                \n",
    "            track_center = track_data['center']\n",
    "            distance = np.sqrt((center[0] - track_center[0])**2 + (center[1] - track_center[1])**2)\n",
    "            \n",
    "            if distance < min_distance and distance < 80:\n",
    "                min_distance = distance\n",
    "                assigned_id = track_id\n",
    "        \n",
    "        # Create new track if no match\n",
    "        if assigned_id is None:\n",
    "            assigned_id = self.next_track_id\n",
    "            self.next_track_id += 1\n",
    "        \n",
    "        # Update track\n",
    "        self.tracks[assigned_id] = {\n",
    "            'center': center,\n",
    "            'last_seen': time.time(),\n",
    "            'class': detection['class']\n",
    "        }\n",
    "        \n",
    "        return assigned_id\n",
    "    \n",
    "    def get_track_color(self, track_id):\n",
    "        \"\"\"Generate consistent color untuk setiap track ID\"\"\"\n",
    "        colors = [\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 0, 0),    # Blue\n",
    "            (0, 0, 255),    # Red\n",
    "            (255, 255, 0),  # Cyan\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Yellow\n",
    "            (128, 0, 128),  # Purple\n",
    "            (255, 165, 0),  # Orange\n",
    "        ]\n",
    "        return colors[track_id % len(colors)]\n",
    "    \n",
    "    def display_thread(self):\n",
    "        \"\"\"Display thread untuk visualization\"\"\"\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get tracked frame from Tracking Buffer\n",
    "                tracked_frame, frame_id, timestamp = self.tracking_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Add performance overlay\n",
    "                self.add_performance_overlay(tracked_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Webcam Object Detection & Tracking', tracked_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.running = False\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.tracks.clear()\n",
    "                    self.next_track_id = 0\n",
    "                    print(\"ğŸ”„ Tracking reset\")\n",
    "                elif key == ord('s'):\n",
    "                    # Save screenshot\n",
    "                    timestamp_str = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    filename = f\"webcam_capture_{timestamp_str}.jpg\"\n",
    "                    cv2.imwrite(filename, tracked_frame)\n",
    "                    print(f\"ğŸ“¸ Screenshot saved: {filename}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Stopped\")\n",
    "    \n",
    "    def add_performance_overlay(self, frame):\n",
    "        \"\"\"Add performance statistics overlay\"\"\"\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        \n",
    "        # Calculate overall FPS (bottleneck from all threads)\n",
    "        overall_fps = min(self.stats['camera_fps'], self.stats['detection_fps'], self.stats['tracking_fps'])\n",
    "        \n",
    "        stats_text = [\n",
    "            f\"ğŸ“¹ Camera FPS: {self.stats['camera_fps']:.1f}\",\n",
    "            f\"ğŸ” Detection FPS: {self.stats['detection_fps']:.1f}\",\n",
    "            f\"ğŸ“Š Batch FPS: {self.stats['batch_fps']:.1f}\",\n",
    "            f\"ğŸ¯ Tracking FPS: {self.stats['tracking_fps']:.1f}\",\n",
    "            f\"âš¡ Overall FPS: {overall_fps:.1f}\",\n",
    "            f\"ğŸ“¦ Batch Size: {self.batch_size}\",\n",
    "            f\"ğŸ”¢ Batches: {self.stats['batches_processed']}\",\n",
    "            f\"ğŸ‘¥ Active Tracks: {len(self.tracks)}\",\n",
    "            f\"ğŸ”„ Buffers: F{self.frame_buffer.qsize()}/D{self.detection_buffer.qsize()}/T{self.tracking_buffer.qsize()}\",\n",
    "            f\"â±ï¸ Runtime: {elapsed:.1f}s\"\n",
    "        ]\n",
    "        \n",
    "        # Background for text\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5, 5), (450, 240), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Add text\n",
    "        for i, text in enumerate(stats_text):\n",
    "            y_pos = 20 + (i * 22)\n",
    "            color = (0, 255, 0) if \"FPS\" in text and any(char.isdigit() for char in text.split(\":\")[1]) and float(''.join(filter(lambda x: x.isdigit() or x == '.', text.split(\":\")[1]))) > 50 else (0, 255, 255)\n",
    "            cv2.putText(frame, text, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Success indicator\n",
    "        if self.stats['batch_fps'] > 100:\n",
    "            cv2.putText(frame, \"ğŸ‰ HIGH PERFORMANCE ACHIEVED!\", (10, 270), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Webcam indicator\n",
    "        cv2.putText(frame, \"ğŸ“¹ LIVE WEBCAM\", (frame.shape[1] - 200, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"ğŸš€ Starting Batched Multi-Thread Webcam Detection & Tracking System\")\n",
    "        print(f\"Architecture: Webcam â†’ Frame Buffer â†’ Batch Detection ({self.batch_size}) â†’ Detection Buffer â†’ Tracking â†’ Tracking Buffer â†’ Display\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        print(\"  'r' - Reset tracking\")\n",
    "        print(\"  's' - Save screenshot\")\n",
    "        \n",
    "        # Start all threads\n",
    "        threads = [\n",
    "            threading.Thread(target=self.camera_thread, daemon=True, name=\"WebcamThread\"),\n",
    "            threading.Thread(target=self.object_detection_thread, daemon=True, name=\"BatchDetectionThread\"),\n",
    "            threading.Thread(target=self.object_tracking_thread, daemon=True, name=\"TrackingThread\"),\n",
    "            threading.Thread(target=self.display_thread, daemon=True, name=\"DisplayThread\")\n",
    "        ]\n",
    "        \n",
    "        # Start threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "            print(f\"âœ… {thread.name} started\")\n",
    "        \n",
    "        try:\n",
    "            # Monitor system performance\n",
    "            while self.running:\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Check performance\n",
    "                if self.stats['batch_fps'] > 100:\n",
    "                    print(f\"ğŸ‰ HIGH BATCH PERFORMANCE: {self.stats['batch_fps']:.1f} FPS!\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nâ¹ï¸ Stopping system...\")\n",
    "            self.running = False\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        for thread in threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=2.0)\n",
    "                print(f\"âœ… {thread.name} stopped\")\n",
    "        \n",
    "        # Final statistics\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        print(f\"\\nğŸ“Š Final Statistics:\")\n",
    "        print(f\"Runtime: {elapsed:.2f}s\")\n",
    "        print(f\"Camera frames: {self.stats['camera_frames']}\")\n",
    "        print(f\"Detection frames: {self.stats['detection_frames']}\")\n",
    "        print(f\"Tracking frames: {self.stats['tracking_frames']}\")\n",
    "        print(f\"Batches processed: {self.stats['batches_processed']}\")\n",
    "        print(f\"Final Camera FPS: {self.stats['camera_fps']:.2f}\")\n",
    "        print(f\"Final Detection FPS: {self.stats['detection_fps']:.2f}\")\n",
    "        print(f\"Final Batch FPS: {self.stats['batch_fps']:.2f}\")\n",
    "        print(f\"Final Tracking FPS: {self.stats['tracking_fps']:.2f}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    engine_path = \"C:/Users/JuhenFW/VSCODE/myproject/yolo11s.engine\"  # Gunakan model TensorRT\n",
    "    # engine_path = \"yolo11m.pt\"    # Atau gunakan model PyTorch\n",
    "    \n",
    "    # Batch size untuk processing\n",
    "    batch_size = 4\n",
    "    buffer_size = 20\n",
    "    \n",
    "    # PERUBAHAN UTAMA: Tidak perlu video_path lagi, langsung menggunakan webcam\n",
    "    system = BatchedWebcamSystem(engine_path, batch_size, buffer_size)\n",
    "    system.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43680040",
   "metadata": {},
   "source": [
    "# For WebCam - Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de5eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "ğŸš€ Starting Batched Multi-Thread Webcam Detection & Tracking System\n",
      "Architecture: Webcam â†’ Frame Buffer â†’ Batch Detection (4) â†’ Detection Buffer â†’ Tracking â†’ Tracking Buffer â†’ Display\n",
      "Batch Size: 4\n",
      "Controls:\n",
      "  'q' - Quit\n",
      "  'r' - Reset tracking\n",
      "  's' - Save screenshot\n",
      "âœ… WebcamThread started\n",
      "ğŸ” Object Detection Thread Started (Batch Size: 4)\n",
      "âœ… BatchDetectionThread started\n",
      "ğŸ¯ Object Tracking Thread Started\n",
      "âœ… TrackingThread started\n",
      "ğŸ–¥ï¸ Display Thread Started\n",
      "âœ… DisplayThread started\n",
      "ğŸ“¹ Webcam Thread Started\n",
      "Loading C:\\Users\\JuhenFW\\VSCODE\\myproject\\yolo11s.engine for TensorRT inference...\n",
      "ğŸ“¹ Camera FPS: 26.5\n",
      "ğŸ” Detection FPS: 14.6 | Batch FPS: 14.6\n",
      "ğŸ¯ Tracking FPS: 14.6\n",
      "ğŸ“¹ Camera FPS: 30.4\n",
      "ğŸ” Detection FPS: 30.3 | Batch FPS: 19.7\n",
      "ğŸ¯ Tracking FPS: 30.3\n",
      "ğŸ“¹ Camera FPS: 30.0\n",
      "ğŸ” Detection FPS: 30.0 | Batch FPS: 22.3\n",
      "ğŸ¯ Tracking FPS: 30.0\n",
      "ğŸ“¹ Camera FPS: 29.8\n",
      "ğŸ” Detection FPS: 29.8 | Batch FPS: 23.8\n",
      "ğŸ¯ Tracking FPS: 29.8\n",
      "ğŸ“¹ Camera FPS: 29.9\n",
      "ğŸ” Detection FPS: 29.9 | Batch FPS: 24.8\n",
      "ğŸ¯ Tracking FPS: 29.9\n",
      "ğŸ“¹ Camera FPS: 18.4\n",
      "ğŸ” Detection FPS: 18.2 | Batch FPS: 23.4\n",
      "ğŸ¯ Tracking FPS: 18.2\n",
      "ğŸ“¹ Camera FPS: 22.3\n",
      "ğŸ” Detection FPS: 22.5 | Batch FPS: 23.2\n",
      "ğŸ¯ Tracking FPS: 22.5\n",
      "ğŸ“¹ Camera FPS: 30.0\n",
      "ğŸ” Detection FPS: 30.0 | Batch FPS: 23.9\n",
      "ğŸ¯ Tracking FPS: 30.0\n",
      "ğŸ¯ Object Tracking Thread Stopped\n",
      "ğŸ–¥ï¸ Display Thread Stopped\n",
      "ğŸ” Object Detection Thread Stopped\n",
      "ğŸ“¹ Camera Thread Stopped\n",
      "\n",
      "ğŸ“Š Final Statistics:\n",
      "Runtime: 36.23s\n",
      "Camera frames: 874\n",
      "Detection frames: 876\n",
      "Tracking frames: 872\n",
      "Batches processed: 219\n",
      "Final Camera FPS: 29.95\n",
      "Final Detection FPS: 29.97\n",
      "Final Batch FPS: 23.92\n",
      "Final Tracking FPS: 29.99\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import queue\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "class BatchedWebcamSystem:\n",
    "    def __init__(self, engine_path, batch_size=32, buffer_size=50):\n",
    "        self.model = YOLO(engine_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        # Shared Memory Buffers\n",
    "        self.frame_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.detection_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        self.tracking_buffer = queue.Queue(maxsize=buffer_size)\n",
    "        \n",
    "        # Thread control\n",
    "        self.running = True\n",
    "        \n",
    "        # Tracking state\n",
    "        self.tracks = {}\n",
    "        self.next_track_id = 0\n",
    "        \n",
    "        # Performance monitoring\n",
    "        self.stats = {\n",
    "            'camera_fps': 0,\n",
    "            'detection_fps': 0,\n",
    "            'tracking_fps': 0,\n",
    "            'batch_fps': 0,\n",
    "            'camera_frames': 0,\n",
    "            'detection_frames': 0,\n",
    "            'tracking_frames': 0,\n",
    "            'batches_processed': 0,\n",
    "            'start_time': time.time()\n",
    "        }\n",
    "        \n",
    "        # Frame dimensions\n",
    "        self.frame_height = 720\n",
    "        self.frame_width = 1280\n",
    "        self.frame_channels = 3\n",
    "    \n",
    "    def camera_thread(self):\n",
    "        \"\"\"Camera Thread - Continuous webcam capture ke Frame Buffer\"\"\"\n",
    "        cap = cv2.VideoCapture(0)  # Webcam default\n",
    "        \n",
    "        # Set webcam properties\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 60)  # Set FPS tinggi untuk webcam\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce latency\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"âŒ Error: Cannot open webcam\")\n",
    "            self.running = False\n",
    "            return\n",
    "        \n",
    "        frame_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ“¹ Webcam Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"âŒ Error: Cannot read from webcam\")\n",
    "                break\n",
    "            \n",
    "            # Resize frame untuk konsistensi\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            \n",
    "            # Add frame to Frame Buffer\n",
    "            if not self.frame_buffer.full():\n",
    "                self.frame_buffer.put((frame.copy(), frame_count, time.time()))\n",
    "                frame_count += 1\n",
    "                self.stats['camera_frames'] += 1\n",
    "            else:\n",
    "                # Skip frame jika buffer penuh\n",
    "                pass\n",
    "            \n",
    "            # Calculate camera FPS\n",
    "            if frame_count % 100 == 0:\n",
    "                elapsed = time.time() - fps_start\n",
    "                self.stats['camera_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                fps_start = time.time()\n",
    "                print(f\"ğŸ“¹ Camera FPS: {self.stats['camera_fps']:.1f}\")\n",
    "        \n",
    "        cap.release()\n",
    "        print(\"ğŸ“¹ Camera Thread Stopped\")\n",
    "    \n",
    "    def object_detection_thread(self):\n",
    "        \"\"\"Object Detection Thread - Batch processing frames\"\"\"\n",
    "        detection_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(f\"ğŸ” Object Detection Thread Started (Batch Size: {self.batch_size})\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                frames_batch = []\n",
    "                frame_ids = []\n",
    "                timestamps = []\n",
    "                \n",
    "                # Collect batch_size frames\n",
    "                for _ in range(self.batch_size):\n",
    "                    try:\n",
    "                        frame, frame_id, timestamp = self.frame_buffer.get(timeout=0.1)\n",
    "                        frames_batch.append(frame)\n",
    "                        frame_ids.append(frame_id)\n",
    "                        timestamps.append(timestamp)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                \n",
    "                if len(frames_batch) > 0:\n",
    "                    # Pad batch if less than batch_size\n",
    "                    while len(frames_batch) < self.batch_size:\n",
    "                        frames_batch.append(frames_batch[-1])\n",
    "                        frame_ids.append(frame_ids[-1])\n",
    "                        timestamps.append(timestamps[-1])\n",
    "                    \n",
    "                    # Run batch inference\n",
    "                    with torch.no_grad():\n",
    "                        batch_results = self.model.predict(\n",
    "                            frames_batch,\n",
    "                            device=0,\n",
    "                            conf=0.25,\n",
    "                            iou=0.45,\n",
    "                            verbose=False,\n",
    "                            stream=False\n",
    "                        )\n",
    "                    \n",
    "                    # Put batch results into Detection Buffer\n",
    "                    for i, (frame, result, frame_id, timestamp) in enumerate(zip(frames_batch, batch_results, frame_ids, timestamps)):\n",
    "                        if not self.detection_buffer.full():\n",
    "                            self.detection_buffer.put((frame, result, frame_id, timestamp))\n",
    "                            detection_count += 1\n",
    "                            self.stats['detection_frames'] += 1\n",
    "                    \n",
    "                    self.stats['batches_processed'] += 1\n",
    "                    \n",
    "                    # Calculate detection FPS\n",
    "                    if detection_count % 100 == 0:\n",
    "                        elapsed = time.time() - fps_start\n",
    "                        self.stats['detection_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                        self.stats['batch_fps'] = (self.stats['batches_processed'] * self.batch_size) / (time.time() - self.stats['start_time'])\n",
    "                        fps_start = time.time()\n",
    "                        print(f\"ğŸ” Detection FPS: {self.stats['detection_fps']:.1f} | Batch FPS: {self.stats['batch_fps']:.1f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Detection error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ” Object Detection Thread Stopped\")\n",
    "    \n",
    "    def object_tracking_thread(self):\n",
    "        \"\"\"Object Tracking Thread - Individual frame tracking\"\"\"\n",
    "        tracking_count = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get detection result\n",
    "                frame, detection_result, frame_id, timestamp = self.detection_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Perform tracking per frame\n",
    "                tracked_frame = self.perform_tracking(frame, detection_result, frame_id)\n",
    "                \n",
    "                # Put to Tracking Buffer\n",
    "                if not self.tracking_buffer.full():\n",
    "                    self.tracking_buffer.put((tracked_frame, frame_id, timestamp))\n",
    "                    tracking_count += 1\n",
    "                    self.stats['tracking_frames'] += 1\n",
    "                \n",
    "                # Calculate tracking FPS\n",
    "                if tracking_count % 100 == 0:\n",
    "                    elapsed = time.time() - fps_start\n",
    "                    self.stats['tracking_fps'] = 100 / elapsed if elapsed > 0 else 0\n",
    "                    fps_start = time.time()\n",
    "                    print(f\"ğŸ¯ Tracking FPS: {self.stats['tracking_fps']:.1f}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Tracking error: {e}\")\n",
    "        \n",
    "        print(\"ğŸ¯ Object Tracking Thread Stopped\")\n",
    "    \n",
    "    def perform_tracking(self, frame, detection_result, frame_id):\n",
    "        \"\"\"Perform object tracking with class name instead of ID\"\"\"\n",
    "        tracked_frame = frame.copy()\n",
    "        \n",
    "        if detection_result.boxes is not None:\n",
    "            boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
    "            confs = detection_result.boxes.conf.cpu().numpy()\n",
    "            classes = detection_result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            current_detections = []\n",
    "            \n",
    "            # Extract detections and class names\n",
    "            for box, conf, cls in zip(boxes, confs, classes):\n",
    "                if conf > 0.25:\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    \n",
    "                    current_detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'center': (center_x, center_y),\n",
    "                        'conf': conf,\n",
    "                        'class': int(cls),\n",
    "                        'class_name': self.model.names[int(cls)]  # Get class name\n",
    "                    })\n",
    "            \n",
    "            # Assign track IDs and display class name\n",
    "            for detection in current_detections:\n",
    "                track_id = self.assign_track_id(detection)\n",
    "                \n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                \n",
    "                # Draw tracking visualization\n",
    "                color = self.get_track_color(track_id)\n",
    "                cv2.rectangle(tracked_frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Display track info with class name\n",
    "                label = f\"ID:{track_id} {detection['class_name']} {detection['conf']:.2f}\"\n",
    "                cv2.putText(tracked_frame, label, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Draw center point\n",
    "                cv2.circle(tracked_frame, detection['center'], 3, color, -1)\n",
    "        \n",
    "        return tracked_frame\n",
    "    \n",
    "    def assign_track_id(self, detection):\n",
    "        \"\"\"Assign track ID using distance-based matching\"\"\"\n",
    "        center = detection['center']\n",
    "        min_distance = float('inf')\n",
    "        assigned_id = None\n",
    "        \n",
    "        # Find closest existing track\n",
    "        for track_id, track_data in list(self.tracks.items()):\n",
    "            if time.time() - track_data['last_seen'] > 2.0:\n",
    "                del self.tracks[track_id]\n",
    "                continue\n",
    "                \n",
    "            track_center = track_data['center']\n",
    "            distance = np.sqrt((center[0] - track_center[0])**2 + (center[1] - track_center[1])**2)\n",
    "            \n",
    "            if distance < min_distance and distance < 80:\n",
    "                min_distance = distance\n",
    "                assigned_id = track_id\n",
    "        \n",
    "        # Create new track if no match\n",
    "        if assigned_id is None:\n",
    "            assigned_id = self.next_track_id\n",
    "            self.next_track_id += 1\n",
    "        \n",
    "        # Update track\n",
    "        self.tracks[assigned_id] = {\n",
    "            'center': center,\n",
    "            'last_seen': time.time(),\n",
    "            'class': detection['class']\n",
    "        }\n",
    "        \n",
    "        return assigned_id\n",
    "    \n",
    "    def get_track_color(self, track_id):\n",
    "        \"\"\"Generate consistent color for each track ID\"\"\"\n",
    "        colors = [\n",
    "            (0, 255, 0),    # Green\n",
    "            (255, 0, 0),    # Blue\n",
    "            (0, 0, 255),    # Red\n",
    "            (255, 255, 0),  # Cyan\n",
    "            (255, 0, 255),  # Magenta\n",
    "            (0, 255, 255),  # Yellow\n",
    "            (128, 0, 128),  # Purple\n",
    "            (255, 165, 0),  # Orange\n",
    "        ]\n",
    "        return colors[track_id % len(colors)]\n",
    "    \n",
    "    def display_thread(self):\n",
    "        \"\"\"Display thread for visualization\"\"\"\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Started\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Get tracked frame from Tracking Buffer\n",
    "                tracked_frame, frame_id, timestamp = self.tracking_buffer.get(timeout=0.1)\n",
    "                \n",
    "                # Add performance overlay\n",
    "                self.add_performance_overlay(tracked_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Webcam Object Detection & Tracking', tracked_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.running = False\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.tracks.clear()\n",
    "                    self.next_track_id = 0\n",
    "                    print(\"ğŸ”„ Tracking reset\")\n",
    "                elif key == ord('s'):\n",
    "                    # Save screenshot\n",
    "                    timestamp_str = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    filename = f\"webcam_capture_{timestamp_str}.jpg\"\n",
    "                    cv2.imwrite(filename, tracked_frame)\n",
    "                    print(f\"ğŸ“¸ Screenshot saved: {filename}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"ğŸ–¥ï¸ Display Thread Stopped\")\n",
    "    \n",
    "    def add_performance_overlay(self, frame):\n",
    "        \"\"\"Add performance statistics overlay\"\"\"\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        \n",
    "        # Calculate overall FPS (bottleneck from all threads)\n",
    "        overall_fps = min(self.stats['camera_fps'], self.stats['detection_fps'], self.stats['tracking_fps'])\n",
    "        \n",
    "        stats_text = [\n",
    "            f\"ğŸ“¹ Camera FPS: {self.stats['camera_fps']:.1f}\",\n",
    "            f\"ğŸ” Detection FPS: {self.stats['detection_fps']:.1f}\",\n",
    "            f\"ğŸ“Š Batch FPS: {self.stats['batch_fps']:.1f}\",\n",
    "            f\"ğŸ¯ Tracking FPS: {self.stats['tracking_fps']:.1f}\",\n",
    "            f\"âš¡ Overall FPS: {overall_fps:.1f}\",\n",
    "            f\"ğŸ“¦ Batch Size: {self.batch_size}\",\n",
    "            f\"ğŸ”¢ Batches: {self.stats['batches_processed']}\",\n",
    "            f\"ğŸ‘¥ Active Tracks: {len(self.tracks)}\",\n",
    "            f\"ğŸ”„ Buffers: F{self.frame_buffer.qsize()}/D{self.detection_buffer.qsize()}/T{self.tracking_buffer.qsize()}\",\n",
    "            f\"â±ï¸ Runtime: {elapsed:.1f}s\"\n",
    "        ]\n",
    "        \n",
    "        # Background for text\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (5, 5), (450, 240), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Add text\n",
    "        for i, text in enumerate(stats_text):\n",
    "            y_pos = 20 + (i * 22)\n",
    "            color = (0, 255, 0) if \"FPS\" in text and any(char.isdigit() for char in text.split(\":\")[1]) and float(''.join(filter(lambda x: x.isdigit() or x == '.', text.split(\":\")[1]))) > 50 else (0, 255, 255)\n",
    "            cv2.putText(frame, text, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Success indicator\n",
    "        if self.stats['batch_fps'] > 100:\n",
    "            cv2.putText(frame, \"ğŸ‰ HIGH PERFORMANCE ACHIEVED!\", (10, 270), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Webcam indicator\n",
    "        cv2.putText(frame, \"ğŸ“¹ LIVE WEBCAM\", (frame.shape[1] - 200, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"ğŸš€ Starting Batched Multi-Thread Webcam Detection & Tracking System\")\n",
    "        print(f\"Architecture: Webcam â†’ Frame Buffer â†’ Batch Detection ({self.batch_size}) â†’ Detection Buffer â†’ Tracking â†’ Tracking Buffer â†’ Display\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        print(\"  'r' - Reset tracking\")\n",
    "        print(\"  's' - Save screenshot\")\n",
    "        \n",
    "        # Start all threads\n",
    "        threads = [\n",
    "            threading.Thread(target=self.camera_thread, daemon=True, name=\"WebcamThread\"),\n",
    "            threading.Thread(target=self.object_detection_thread, daemon=True, name=\"BatchDetectionThread\"),\n",
    "            threading.Thread(target=self.object_tracking_thread, daemon=True, name=\"TrackingThread\"),\n",
    "            threading.Thread(target=self.display_thread, daemon=True, name=\"DisplayThread\")\n",
    "        ]\n",
    "        \n",
    "        # Start threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "            print(f\"âœ… {thread.name} started\")\n",
    "        \n",
    "        try:\n",
    "            # Monitor system performance\n",
    "            while self.running:\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Check performance\n",
    "                if self.stats['batch_fps'] > 100:\n",
    "                    print(f\"ğŸ‰ HIGH BATCH PERFORMANCE: {self.stats['batch_fps']:.1f} FPS!\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nâ¹ï¸ Stopping system...\")\n",
    "            self.running = False\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        for thread in threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=2.0)\n",
    "                print(f\"âœ… {thread.name} stopped\")\n",
    "        \n",
    "        # Final statistics\n",
    "        elapsed = time.time() - self.stats['start_time']\n",
    "        print(f\"\\nğŸ“Š Final Statistics:\")\n",
    "        print(f\"Runtime: {elapsed:.2f}s\")\n",
    "        print(f\"Camera frames: {self.stats['camera_frames']}\")\n",
    "        print(f\"Detection frames: {self.stats['detection_frames']}\")\n",
    "        print(f\"Tracking frames: {self.stats['tracking_frames']}\")\n",
    "        print(f\"Batches processed: {self.stats['batches_processed']}\")\n",
    "        print(f\"Final Camera FPS: {self.stats['camera_fps']:.2f}\")\n",
    "        print(f\"Final Detection FPS: {self.stats['detection_fps']:.2f}\")\n",
    "        print(f\"Final Batch FPS: {self.stats['batch_fps']:.2f}\")\n",
    "        print(f\"Final Tracking FPS: {self.stats['tracking_fps']:.2f}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    engine_path = \"C:/Users/JuhenFW/VSCODE/myproject/yolo11s.engine\"  # Gunakan model TensorRT\n",
    "    # engine_path = \"yolo11m.pt\"    # Atau gunakan model PyTorch\n",
    "    \n",
    "    # Batch size untuk processing\n",
    "    batch_size = 4\n",
    "    buffer_size = 20\n",
    "    \n",
    "    # Initialize and run the system\n",
    "    system = BatchedWebcamSystem(engine_path, batch_size, buffer_size)\n",
    "    system.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
